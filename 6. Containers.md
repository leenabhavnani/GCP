### Notes

- Kubernetes is an open-source platform for managing containerized workloads and services.
- It makes it easy to orchestrate many containers on many hosts, scale them as microservices, and easily deploy rollouts and rollbacks.
- GKE is a Google-hosted managed Kubernetes service in the cloud.
- In GKE, the load balancer is created as a network load balancer.
- **Anthos** is a hybrid and multi-cloud solution powered by the latest innovations in distributed systems and service management software from Google.
- It has centralized management through a central control plane that supports policy-based application lifecycle delivery across hybrid and multiple cloud environments.
- **Google Kubernetes Engine**: Is a managed, production-ready environment for deploying containerized applications.
- **GKE On-Prem**: Is a turnkey, production-grade, conformant version of Kubernetes with a best-practice configuration pre-loaded.
- Provides access to container services on Google Cloud such as Cloud Build, Container Registry, and Cloud Audit Logs.
- There are “Four Golden Signals” that measure a system’s performance and reliability.
   - They are latency, traffic, saturation, and errors
   - Latency measures how long it takes a particular part of a system to return a result.
   - Sample latency metrics include: Page load latency Number of requests waiting for a thread Query duration Service response time Transaction duration Time to first response Time to complete data return The next signal is traffic, which measures how many requests are reaching your system.
- The next signal is traffic, which measures how many requests are reaching your system.
- Sample traffic metrics include: number of HTTP requests per second number of requests for static vs dynamic content Network I/O number of concurrent sessions number of transactions per second number of retrievals per second number of active requests number of write ops number of read ops And number of active connections
- The third signal is saturation, which measures how close to capacity a system is.
- Sample capacity metrics include: % memory utilization % thread pool utilization % cache utilization % disk utilization % CPU utilization Disk quota Memory quota number of available connections And number of users on the system
- The fourth signal is errors, which are events that measure system failures or other issues
- Wrong answers or incorrect content number of 400/500 HTTP codes number of failed requests number of exceptions number of stack traces Servers that fail liveness checks And number of dropped connections
- **Service level indicators**, or SLIs, are carefully selected monitoring metrics that measure one aspect of a service's reliability.
- A **Service level objective**, or SLO, combines a service level indicator with a target reliability.
- **Service Level Agreements**, or SLAs, which are commitments made to your customers that your systems and applications will have only a certain amount of “down time.”
- An SLA describes the minimum levels of service that you promise to provide to your customers and what happens when you break that promise.
- Google Cloud’s integrated logging tools -
    - Cloud Logging allows users to collect, store, search, analyze, monitor, and alert on log entries and events.
    - Agent logs use a Google-customized and packaged Fluentd agent that can be installed on any AWS or Google Cloud VM to ingest log data from Google Cloud instances–for example, Compute Engine, Managed VMs, or Containers–and AWS EC2 instances
    - Network logs provide both network and security operations with in-depth network service telemetry.
    - Service logs provide access to logs created by developers deploying code to Google Cloud.
- **Cloud Trace**, based on the tools Google uses on its production services, is a tracing system that collects latency data from your distributed applications and displays it in the Google Cloud console. Trace can capture traces from applications deployed on App Engine, Compute Engine VMs, and Google Kubernetes Engine containers.
- **Cloud Profiler** presents the call hierarchy and resource consumption of the relevant function in an interactive flame graph that helps developers understand which paths consume the most resources and the different ways in which their code is actually called.
